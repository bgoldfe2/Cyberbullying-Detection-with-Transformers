{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOgeD/DdktxlGecAb+ZgliL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"premium"},"cells":[{"cell_type":"markdown","source":["# Initial Reproduction and Three Extensions of the Cyberbullying Detections Using Transformers Paper\n","### Initial Objective is to recreate\n","  * Attempt to repeat the origin numbers using same hyperparamters\n","  * This will serve as the baseline\n","\n","### Experiment #1 Recreate as an ensemble of binary modules per label\n","  * Have last layer be binary (2) output\n","  * Apply SoftMax layer for probabilities\n","  * Create ensemble with each of the outputs per label\n","  * Compare outputs\n","\n","### Experiment #2 Vertical data augmentation using synthetic data generation\n","  * Leverage GPT-3 for custom data generation per label\n","  * Use as additional data for training\n","  * Compare Outputs\n","\n","### Experiment #3 Horizontal data augmentation using additional label and context content\n","  * Add in additional labels of data serving as additional binary modules for the ensemble\n","  * Add in personal context information to serve as \"normal\" baseline for that individual "],"metadata":{"id":"PjqoB10j7N-V"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gcRbo8UAJ0oA","executionInfo":{"status":"ok","timestamp":1669923520517,"user_tz":300,"elapsed":40391,"user":{"displayName":"Bruce Goldfeder","userId":"01568302622654738051"}},"outputId":"a6d0c8a7-36e5-40ca-a644-b7e30f960482"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/Github/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DiIKv0p_Lsxc","executionInfo":{"status":"ok","timestamp":1669923553009,"user_tz":300,"elapsed":263,"user":{"displayName":"Bruce Goldfeder","userId":"01568302622654738051"}},"outputId":"2d6a7cc5-2401-427b-9703-01901b584a11"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Github\n"]}]},{"cell_type":"code","source":["username = 'bgoldfe2'\n","repository = 'Cyberbullying-Detection-with-Transformers'"],"metadata":{"id":"jbcYyBZPL9YG","executionInfo":{"status":"ok","timestamp":1669923555642,"user_tz":300,"elapsed":391,"user":{"displayName":"Bruce Goldfeder","userId":"01568302622654738051"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["For working with Git for each session you need to move the Github/ssh folder to /root/ or cd ~ and rename it to .ssh via mv ssh .ssh copy it with the command cp -R /content/drive/MyDrive/Github/Cyberbullying-Detection-with-Transformers/ssh .\n","\n","What a Kludge!!!!"],"metadata":{"id":"97KO9XCo-VC_"}},{"cell_type":"code","source":["%cd {repository}"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jX_tMlrVPIBS","executionInfo":{"status":"ok","timestamp":1669923559988,"user_tz":300,"elapsed":294,"user":{"displayName":"Bruce Goldfeder","userId":"01568302622654738051"}},"outputId":"fda8c97b-86da-4549-c9ae-ee70a02f9dcf"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Github/Cyberbullying-Detection-with-Transformers\n"]}]},{"cell_type":"code","source":["!git status"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X81emmSBcCck","executionInfo":{"status":"ok","timestamp":1669923607552,"user_tz":300,"elapsed":16299,"user":{"displayName":"Bruce Goldfeder","userId":"01568302622654738051"}},"outputId":"5848af7c-950d-459e-fa9b-0455f79f8d4e"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["On branch main\n","Your branch is up to date with 'origin/main'.\n","\n","Changes not staged for commit:\n","  (use \"git add <file>...\" to update what will be committed)\n","  (use \"git checkout -- <file>...\" to discard changes in working directory)\n","\n","\t\u001b[31mmodified:   CyberTransformer.ipynb\u001b[m\n","\t\u001b[31mmodified:   Dataset/test.csv\u001b[m\n","\t\u001b[31mmodified:   Dataset/train.csv\u001b[m\n","\t\u001b[31mmodified:   Dataset/valid.csv\u001b[m\n","\n","no changes added to commit (use \"git add\" and/or \"git commit -a\")\n"]}]},{"cell_type":"code","source":["!git config --global user.email \"bgoldfe2@gmu.edu\"\n","!git config --global user.name \"Bruce Goldfeder\""],"metadata":{"id":"UYdD-GwxcPHz","executionInfo":{"status":"ok","timestamp":1669924359518,"user_tz":300,"elapsed":284,"user":{"displayName":"Bruce Goldfeder","userId":"01568302622654738051"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["!pip install -r requirements.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HLxTt7YVPQYX","executionInfo":{"status":"ok","timestamp":1669924375477,"user_tz":300,"elapsed":13252,"user":{"displayName":"Bruce Goldfeder","userId":"01568302622654738051"}},"outputId":"9bfaaec6-83f8-4689-e037-537ce50cc0c2"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.24.0-py3-none-any.whl (5.5 MB)\n","\u001b[K     |████████████████████████████████| 5.5 MB 4.3 MB/s \n","\u001b[?25hCollecting sentencepiece\n","  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[K     |████████████████████████████████| 1.3 MB 51.7 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers->-r requirements.txt (line 1)) (2.23.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers->-r requirements.txt (line 1)) (21.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers->-r requirements.txt (line 1)) (2022.6.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers->-r requirements.txt (line 1)) (4.64.1)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","\u001b[K     |████████████████████████████████| 7.6 MB 35.6 MB/s \n","\u001b[?25hCollecting huggingface-hub<1.0,>=0.10.0\n","  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n","\u001b[K     |████████████████████████████████| 182 kB 65.8 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers->-r requirements.txt (line 1)) (3.8.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers->-r requirements.txt (line 1)) (6.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers->-r requirements.txt (line 1)) (1.21.6)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers->-r requirements.txt (line 1)) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers->-r requirements.txt (line 1)) (3.0.9)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers->-r requirements.txt (line 1)) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers->-r requirements.txt (line 1)) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers->-r requirements.txt (line 1)) (2022.9.24)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers->-r requirements.txt (line 1)) (2.10)\n","Installing collected packages: tokenizers, huggingface-hub, transformers, sentencepiece\n","Successfully installed huggingface-hub-0.11.1 sentencepiece-0.1.97 tokenizers-0.13.2 transformers-4.24.0\n"]}]},{"cell_type":"code","source":["%cd Scripts/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XFwDF2OHQS8X","executionInfo":{"status":"ok","timestamp":1669924395200,"user_tz":300,"elapsed":259,"user":{"displayName":"Bruce Goldfeder","userId":"01568302622654738051"}},"outputId":"0b773bb0-0782-437e-e8c3-3449e5b49cfd"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Github/Cyberbullying-Detection-with-Transformers/Scripts\n"]}]},{"cell_type":"code","source":["# Test run for regression testing\n","!python3 train.py --split 'no'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H57OkV8pqhMq","outputId":"9e2f8c32-54d4-41a2-d52f-2281fd82ac33"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'Gender', 'Others', 'Age', 'Notcb', 'Ethnicity', 'Religion'}\n","train len - 2126, valid len - 9541, test len - 9541\n","Unnamed: 0\n","text\n","label\n","target\n","train example text --  @NOKIgivesuWINGZ I love my baby @ShoRtTurtLe412 fuck all you dumb niggers hes all I need !!&lt;~I thought u loved my brother @YeaItsLoopy :( \n","with target --  Ethnicity\n","Downloading: 100% 232k/232k [00:00<00:00, 316kB/s]\n","Downloading: 100% 28.0/28.0 [00:00<00:00, 19.1kB/s]\n","Downloading: 100% 570/570 [00:00<00:00, 391kB/s]\n","train_dataset object is of type --  <class 'dataset.DatasetBert'>\n","Print Whole object at location 1 --  tensor([  101,  1030,  2053,  3211,  5856,  6961, 25974,  2075,  2480,  1045,\n","         2293,  2026,  3336,  1030,  2460, 20689,  9286, 23632,  2475,  6616,\n","         2035,  2017, 12873,  9152, 13327,  2015,  2002,  2015,  2035,  1045,\n","         2342,   999,   999,  1004,  8318,  1025,  1066,  1045,  2245,  1057,\n","         3866,  2026,  2567,  1030,  6300,  4886,  3215,  4135,  7361,  2100,\n","         1024,  1006,   102,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0])\n","token example is --  ['[CLS]', '@', 'no', '##ki', '##gi', '##ves', '##uw', '##ing', '##z', 'i', 'love', 'my', 'baby', '@', 'short', '##tur', '##tle', '##41', '##2', 'fuck', 'all', 'you', 'dumb', 'ni', '##gger', '##s', 'he', '##s', 'all', 'i', 'need', '!', '!', '&', 'lt', ';', '~', 'i', 'thought', 'u', 'loved', 'my', 'brother', '@', 'ye', '##ai', '##ts', '##lo', '##op', '##y', ':', '(', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n","Downloading: 100% 440M/440M [00:06<00:00, 66.2MB/s]\n","Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","109531974\n","---Starting Training---\n","Epoch 1/1\n","----------\n"," 10% 13/133 [04:34<41:59, 21.00s/it, loss=1.95]"]}]}]}